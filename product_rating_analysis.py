# -*- coding: utf-8 -*-
"""product_rating_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18tZHzpL4XBJhccle42REnB5FWUTr5qfi

#**SENTIMENT ANALYSIS ON AMAZON PRODUCT'S REVIEWS**
"""

!pip install textblob

# Import libraries
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import nltk
nltk.download('stopwords')
import nltk
nltk.download('punkt')

from google.colab import drive
drive.mount('/content/drive')

"""# New Section"""

from google.colab import drive
drive.mount('/content/drive')

"""##IMPORTING DATA"""

# Read Excel file
df = pd.read_excel('/content/drive/MyDrive/sample_data/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.xlsx')



# Convert 'reviews.text' column to string
df['reviews.text'] = df['reviews.text'].astype(str)

"""##PREPROCESSING DATA"""

# Preprocess data
stop_words = set(stopwords.words('english'))
text = df['reviews.text'].to_string()
import re

def find_sentences(text):
    # split text into sentences using regular expressions
    sent = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?)\s', text)
    return sent

sentences = find_sentences(text)

df['text'] = df['reviews.text'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if word.isalpha() and word.lower() not in stop_words]))
df['sentiment'] = df['reviews.rating'].apply(lambda x: 'positive' if x >= 4 else 'negative')

"""###TRAIN - TEST SPLITING AND VECTORIZATION"""

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)

# Vectorize text data
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

"""###MODEL FITTING"""

# Train Naive Bayes classifier
clf = MultinomialNB()
clf.fit(X_train_vectorized, y_train)

# Predict sentiment for test data
y_pred = clf.predict(X_test_vectorized)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)

"""##TESTING ON TEST DATA

###IMPORTING TEST DATA AND CONVERTING TO STRING
"""

df = pd.read_excel('/content/drive/MyDrive/sample_data/Test_file.xlsx')
test = df['text']
df['text'] = df['text'].astype(str)

"""###PREPROCESSING"""

# Preprocess data
stop_words = set(stopwords.words('english'))
text = df['text'].to_string()
import re

def find_sentences(text):
    # split text into sentences using regular expressions
    sent = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?)\s', text)
    return sent

sentences = find_sentences(text)

df['text'] = df['text'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if word.isalpha() and word.lower() not in stop_words]))

"""###PREDICTION"""

test_vectorized = vectorizer.transform(df['text'])
y_pred = clf.predict(test_vectorized)

"""###EXPORTING OUTPUTS TO CSV FILE"""

pred = pd.DataFrame(y_pred,columns=['Output'])
sub = pd.concat([test,pred],axis=1)
sub.set_index('text',inplace=True)
sub.to_csv(f"Submission_file.csv")

